{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13646365,"sourceType":"datasetVersion","datasetId":8675019}],"dockerImageVersionId":31193,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-08T11:04:27.719425Z","iopub.execute_input":"2025-11-08T11:04:27.719598Z","iopub.status.idle":"2025-11-08T11:04:29.663496Z","shell.execute_reply.started":"2025-11-08T11:04:27.719581Z","shell.execute_reply":"2025-11-08T11:04:29.662447Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =============================================\n# COMPLETE RSUNet SPEECH DENOISING PIPELINE\n# (Corrected SNR Mixing + Training + Denoising)\n# =============================================\n\n# ---\n# NOTE: This code has been cleaned of non-printable\n# characters (like U+00A0) that cause SyntaxErrors\n# after copy-pasting.\n# ---\n\nimport os\nimport re\nimport numpy as np\nimport librosa\nimport soundfile as sf\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport IPython.display as ipd\n\n# -------------------------------\n# 1Ô∏è‚É£ PATHS\n# -------------------------------\nCLEAN_DIR = \"/kaggle/input/datasetnew/clean_wav/clean_wav\"\nNOISE_DIR = \"/kaggle/input/datasetnew/noise_wav/noise_wav\"\nMIX_DIR   = \"/kaggle/working/mixed_snr_wav\"\nSTFT_DIR  = \"/kaggle/working/dataset\"\nENHANCED_DIR = \"/kaggle/working/enhanced_audio\"\n\nfor d in [MIX_DIR, STFT_DIR, ENHANCED_DIR]:\n    os.makedirs(d, exist_ok=True)\n    os.makedirs(os.path.join(STFT_DIR,\"noisy_mag\"), exist_ok=True)\n    os.makedirs(os.path.join(STFT_DIR,\"clean_mag\"), exist_ok=True)\n    os.makedirs(os.path.join(STFT_DIR,\"phase\"), exist_ok=True)\n\n# -------------------------------\n# 2Ô∏è‚É£ SNR MIXING FUNCTIONS (CORRECTED)\n# -------------------------------\ndef calculate_rms(audio):\n    return np.sqrt(np.mean(audio**2))\n\ndef adjust_noise_to_snr(clean, noise, target_snr_db):\n    clean_rms = calculate_rms(clean)\n    noise_rms = calculate_rms(noise)\n    snr_linear = 10 ** (target_snr_db / 10)\n    target_noise_rms = clean_rms / (np.sqrt(snr_linear) + 1e-8)\n    scaling_factor = target_noise_rms / (noise_rms + 1e-8)\n    return noise * scaling_factor\n\ndef mix_at_snr(clean, noise, target_snr_db):\n    min_len = min(len(clean), len(noise))\n    clean, noise = clean[:min_len], noise[:min_len]\n    \n    # Normalize clean audio\n    clean = clean / (np.max(np.abs(clean)) + 1e-8)\n    \n    # Scale noise to target SNR\n    scaled_noise = adjust_noise_to_snr(clean, noise, target_snr_db)\n    \n    # Mix\n    mixed = clean + scaled_noise\n    \n    # --- ‚ö†Ô∏è CRITICAL FIX HERE ‚ö†Ô∏è ---\n    # DO NOT re-normalize the mixed signal. This breaks the\n    # mathematical relationship to the clean signal.\n    # Instead, clip to prevent distortion if it exceeds 1.0.\n    mixed = np.clip(mixed, -1.0, 1.0)\n    # --- END FIX ---\n    \n    actual_snr = 10*np.log10(np.mean(clean**2)/(np.mean(scaled_noise**2)+1e-8))\n    return mixed, scaled_noise, actual_snr\n\ndef prepare_snr_mixes(clean_dir, noise_dir, mix_dir, snr_levels=[-5,0,5,10], sr=16000):\n    clean_files = sorted([f for f in os.listdir(clean_dir) if f.endswith(\".wav\")])\n    noise_files = sorted([f for f in os.listdir(noise_dir) if f.endswith(\".wav\")])\n    print(f\"Processing {len(clean_files)} clean files and {len(noise_files)} noise files\")\n\n    for clean_file in tqdm(clean_files, desc=\"Mixing audio\"):\n        clean_path = os.path.join(clean_dir, clean_file)\n        clean_audio, _ = librosa.load(clean_path, sr=sr)\n        for noise_file in noise_files:\n            noise_path = os.path.join(noise_dir, noise_file)\n            noise_audio, _ = librosa.load(noise_path, sr=sr)\n            for snr_db in snr_levels:\n                mixed_audio, scaled_noise, actual_snr = mix_at_snr(clean_audio, noise_audio, snr_db)\n                mix_name = f\"{clean_file[:-4]}_{noise_file[:-4]}_snr{snr_db}dB.wav\"\n                sf.write(os.path.join(mix_dir, mix_name), mixed_audio, sr)\n                if clean_files.index(clean_file)<2 and noise_files.index(noise_file)<2:\n                    print(f\"Target SNR: {snr_db} dB, Actual SNR: {actual_snr:.2f} dB\")\n    print(f\"Mixed files created: {len(os.listdir(mix_dir))}\")\n\n# Regenerate correct SNR mixtures\n# (Remember to delete old MIX_DIR and STFT_DIR first)\nprepare_snr_mixes(CLEAN_DIR, NOISE_DIR, MIX_DIR)\n\n# -------------------------------\n# 3Ô∏è‚É£ STFT DATASET PREPARATION (NOW CORRECT)\n# -------------------------------\ndef prepare_stft_dataset(clean_dir, mixed_dir, output_root, sr=16000, n_fft=1024, hop_length=256):\n    mixed_files = [f for f in os.listdir(mixed_dir) if f.endswith(\".wav\")]\n    for f in tqdm(mixed_files, desc=\"Creating STFT\"):\n        clean_id = f.split(\"_\")[0]\n        clean_path = os.path.join(clean_dir, clean_id+\".wav\")\n        if not os.path.exists(clean_path):\n            continue\n            \n        # Load the (now correctly-mixed) noisy file\n        noisy, _ = librosa.load(os.path.join(mixed_dir,f), sr=sr)\n        \n        # Load the original clean file\n        clean_orig, _ = librosa.load(clean_path, sr=sr)\n        \n        min_len = min(len(noisy), len(clean_orig))\n        noisy = noisy[:min_len]\n        clean_orig = clean_orig[:min_len]\n        \n        # --- ‚ö†Ô∏è ALIGNMENT FIX ---\n        # We must create the clean_mag from the *same normalized clean signal*\n        # that was used in the mixing process.\n        clean_normalized = clean_orig / (np.max(np.abs(clean_orig)) + 1e-8)\n        # --- END ALIGNMENT FIX ---\n\n        noisy_stft = librosa.stft(noisy, n_fft=n_fft, hop_length=hop_length)\n        \n        # Use the normalized clean signal for the target\n        clean_stft = librosa.stft(clean_normalized, n_fft=n_fft, hop_length=hop_length)\n        \n        noisy_mag, clean_mag, phase = np.abs(noisy_stft), np.abs(clean_stft), np.angle(noisy_stft)\n        base_name = f.replace(\".wav\",\"\")\n        np.save(os.path.join(output_root,\"noisy_mag\",f\"{base_name}_noisy_mag.npy\"), noisy_mag)\n        np.save(os.path.join(output_root,\"clean_mag\",f\"{base_name}_clean_mag.npy\"), clean_mag)\n        np.save(os.path.join(output_root,\"phase\",f\"{base_name}_phase.npy\"), phase)\n\nprepare_stft_dataset(CLEAN_DIR, MIX_DIR, STFT_DIR)\n\n# -------------------------------\n# 4Ô∏è‚É£ DATASET CLASS\n# -------------------------------\nclass SpeechDataset(Dataset):\n    def __init__(self, noisy_dir, clean_dir, max_frames=256):\n        self.noisy_files = sorted([f for f in os.listdir(noisy_dir) if f.endswith(\".npy\")])\n        self.clean_files = sorted([f for f in os.listdir(clean_dir) if f.endswith(\".npy\")])\n        self.noisy_dir, self.clean_dir, self.max_frames = noisy_dir, clean_dir, max_frames\n\n    def pad_or_crop(self, x):\n        freq,time = x.shape\n        if time < self.max_frames:\n            pad = np.zeros((freq,self.max_frames-time))\n            x = np.concatenate([x,pad],axis=1)\n        else:\n            x = x[:,:self.max_frames]\n        return x\n\n    def __len__(self):\n        return len(self.noisy_files)\n\n    def __getitem__(self, idx):\n        noisy = np.load(os.path.join(self.noisy_dir,self.noisy_files[idx]))\n        clean = np.load(os.path.join(self.clean_dir,self.clean_files[idx]))\n        noisy, clean = self.pad_or_crop(noisy), self.pad_or_crop(clean)\n        return torch.tensor(noisy).unsqueeze(0).float(), torch.tensor(clean).unsqueeze(0).float()\n\nnoisy_dir_stft = os.path.join(STFT_DIR,\"noisy_mag\")\nclean_dir_stft = os.path.join(STFT_DIR,\"clean_mag\")\ndataset = SpeechDataset(noisy_dir_stft, clean_dir_stft, max_frames=256)\ntrain_len = int(0.8*len(dataset))\nval_len   = int(0.1*len(dataset))\ntest_len  = len(dataset)-train_len-val_len\ntrain_ds, val_ds, test_ds = random_split(dataset,[train_len,val_len,test_len])\ntrain_dl = DataLoader(train_ds,batch_size=8,shuffle=True)\nval_dl   = DataLoader(val_ds,batch_size=8)\ntest_dl  = DataLoader(test_ds,batch_size=8)\nprint(f\"Dataset sizes ‚Äî Train: {train_len}, Val: {val_len}, Test: {test_len}\")\n\n# -------------------------------\n# 5Ô∏è‚É£ RSUNET MODEL\n# -------------------------------\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_c, out_c):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_c, out_c, 3, padding=1)\n        self.bn1 = nn.BatchNorm2d(out_c)\n        self.conv2 = nn.Conv2d(out_c, out_c, 3, padding=1)\n        self.bn2 = nn.BatchNorm2d(out_c)\n        self.skip = nn.Conv2d(in_c,out_c,1) if in_c!=out_c else nn.Identity()\n    def forward(self,x):\n        residual = self.skip(x)\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.bn2(self.conv2(x))\n        return F.relu(x+residual)\n\nclass RSUNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.enc1 = ResidualBlock(1,32)\n        self.enc2 = ResidualBlock(32,64)\n        self.enc3 = ResidualBlock(64,128)\n        self.pool = nn.MaxPool2d(2)\n        self.bottleneck = ResidualBlock(128,256)\n        self.up3 = nn.ConvTranspose2d(256,128,2,stride=2)\n        self.dec3 = ResidualBlock(256,128)\n        self.up2 = nn.ConvTranspose2d(128,64,2,stride=2)\n        self.dec2 = ResidualBlock(128,64)\n        self.up1 = nn.ConvTranspose2d(64,32,2,stride=2)\n        self.dec1 = ResidualBlock(64,32)\n        self.out_conv = nn.Conv2d(32,1,1)\n\n    def crop_or_pad(self, src, target):\n        diffY = target.size(2)-src.size(2)\n        diffX = target.size(3)-src.size(3)\n        return F.pad(src, [diffX//2,diffX-diffX//2,diffY//2,diffY-diffY//2])\n\n    def forward(self,x):\n        e1=self.enc1(x)\n        e2=self.enc2(self.pool(e1))\n        e3=self.enc3(self.pool(e2))\n        b = self.bottleneck(self.pool(e3))\n        d3 = self.up3(b); d3=self.crop_or_pad(d3,e3); d3=torch.cat([d3,e3],1); d3=self.dec3(d3)\n        d2 = self.up2(d3); d2=self.crop_or_pad(d2,e2); d2=torch.cat([d2,e2],1); d2=self.dec2(d2)\n        d1 = self.up1(d2); d1=self.crop_or_pad(d1,e1); d1=torch.cat([d1,e1],1); d1=self.dec1(d1)\n        out = self.out_conv(d1)\n        return out\n\n# -------------------------------\n# 6Ô∏è‚É£ TRAINING FUNCTION\n# -------------------------------\ndef train_model(model, train_dl, val_dl, name, epochs=30, lr=1e-3, patience=7):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = model.to(device)\n    criterion = nn.MSELoss()\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n    best_val_loss=float('inf'); patience_counter=0\n    train_losses,val_losses=[],[]\n    \n    for epoch in range(epochs):\n        model.train(); train_loss=0\n        for x,y in train_dl:\n            x,y=x.to(device),y.to(device)\n            optimizer.zero_grad()\n            loss=criterion(model(x),y)\n            loss.backward(); optimizer.step()\n            train_loss+=loss.item()\n        train_loss/=len(train_dl)\n\n        model.eval(); val_loss=0\n        with torch.no_grad():\n            for x,y in val_dl:\n                x,y=x.to(device),y.to(device)\n                val_loss+=criterion(model(x),y).item()\n        val_loss/=len(val_dl)\n\n        train_losses.append(train_loss)\n        val_losses.append(val_loss)\n\n        if val_loss<best_val_loss:\n            best_val_loss=val_loss\n            patience_counter=0\n            torch.save({'model_state_dict':model.state_dict()}, f\"/kaggle/working/best_{name}.pth\")\n        else:\n            patience_counter+=1\n        if patience_counter>=patience:\n            print(f\"Early stopping at epoch {epoch+1}\")\n            break\n        if (epoch+1)%10==0:\n            print(f\"Epoch {epoch+1}: Train Loss {train_loss:.6f}, Val Loss {val_loss:.6f}\")\n    \n    plt.figure(figsize=(10,5))\n    plt.plot(train_losses,label='Train'); plt.plot(val_losses,label='Val')\n    plt.title(f'{name} Training'); plt.xlabel('Epoch'); plt.ylabel('MSE Loss'); plt.legend(); plt.grid(True)\n    plt.show()\n    return model\n\n# -------------------------------\n# 7Ô∏è‚É£ SNR CALCULATION (NOW CORRECT)\n# -------------------------------\ndef calculate_snr_proper(clean,noisy):\n    # This function now works because 'clean' and 'noisy'\n    # are derived from the same aligned, normalized source.\n    min_len=min(len(clean),len(noisy))\n    clean,noisy=clean[:min_len],noisy[:min_len]\n    noise=noisy-clean\n    return 10*np.log10(np.mean(clean**2)/(np.mean(noise**2)+1e-8))\n\n# -------------------------------\n# 8Ô∏è‚É£ AUDIO RECONSTRUCTION\n# -------------------------------\ndef reconstruct_audio(model,noisy_mag_path,phase_path,output_dir,sr=16000,max_frames=256):\n    os.makedirs(output_dir,exist_ok=True)\n    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model=model.to(device); model.eval()\n\n    noisy_mag = np.load(noisy_mag_path)\n    phase = np.load(phase_path)\n    freq,time=noisy_mag.shape\n    if time<max_frames:\n        noisy_mag_input=np.concatenate([noisy_mag,np.zeros((freq,max_frames-time))],axis=1)\n    else:\n        noisy_mag_input=noisy_mag[:,:max_frames]\n\n    noisy_tensor=torch.tensor(noisy_mag_input).unsqueeze(0).unsqueeze(0).float().to(device)\n    with torch.no_grad():\n        enhanced_mag=model(noisy_tensor).cpu().squeeze().numpy()\n\n    freq_mag,time_mag = enhanced_mag.shape\n    freq_phase,time_phase=phase.shape\n    if time_phase<time_mag:\n        phase_aligned=np.concatenate([phase,np.zeros((freq_phase,time_mag-time_phase))],axis=1)\n    else:\n        phase_aligned=phase[:,:time_mag]\n\n    enhanced_stft=enhanced_mag*np.exp(1j*phase_aligned)\n    enhanced_audio=librosa.istft(enhanced_stft)\n\n    output_path=os.path.join(output_dir, os.path.basename(noisy_mag_path).replace(\"_noisy_mag.npy\",\"_enhanced.wav\"))\n    sf.write(output_path, enhanced_audio, sr)\n    print(f\"Saved enhanced audio: {output_path}\")\n    return output_path\n\n# -------------------------------\n# 9Ô∏è‚É£ TRAIN + DENOSING EXECUTION (CORRECTED)\n# -------------------------------\nprint(\"Training RSUNet on corrected dataset...\")\nrsunet = RSUNet()\ntrained_model = train_model(rsunet, train_dl, val_dl, \"rsunet_fixed\", epochs=30)\n\n# Evaluate first 3 samples\nfiles = sorted(os.listdir(noisy_dir_stft))[:3]\nfor idx,f in enumerate(files):\n    clean_id = f.split(\"_\")[0]\n    noisy_path = os.path.join(noisy_dir_stft,f)\n    phase_path = os.path.join(STFT_DIR,\"phase\",f.replace(\"_noisy_mag.npy\",\"_phase.npy\"))\n    clean_wav_path = os.path.join(CLEAN_DIR, clean_id+\".wav\")\n    \n    # --- THIS FIX IS RETAINED ---\n    # Find the corresponding .wav file, not just the first one\n    base_name = f.replace(\"_noisy_mag.npy\", \"\")\n    noisy_wav_path = os.path.join(MIX_DIR, base_name + \".wav\")\n    # --- END FIX ---\n\n    enhanced_wav_path = reconstruct_audio(trained_model,noisy_path,phase_path,ENHANCED_DIR)\n    \n    # Load original clean for reference\n    clean_orig, _ = librosa.load(clean_wav_path, sr=16000)\n    \n    # Load the (correctly mixed) noisy file\n    noisy, _ = librosa.load(noisy_wav_path, sr=16000)\n    \n    # Load the enhanced file\n    enhanced, _ = librosa.load(enhanced_wav_path, sr=16000)\n    \n    # --- ‚ö†Ô∏è EVALUATION FIX ---\n    # We must compare all signals to the *normalized* clean signal,\n    # since that is what the model was trained on and what the\n    # noisy signal was built from.\n    min_len = min(len(clean_orig), len(noisy), len(enhanced))\n    clean_orig = clean_orig[:min_len]\n    noisy = noisy[:min_len]\n    enhanced = enhanced[:min_len]\n    \n    # Use the same normalization that was used for training\n    clean_normalized = clean_orig / (np.max(np.abs(clean_orig)) + 1e-8)\n    \n    # Now, calculate SNR using this aligned, normalized clean signal\n    in_snr = calculate_snr_proper(clean_normalized, noisy)\n    out_snr = calculate_snr_proper(clean_normalized, enhanced)\n    # --- END EVALUATION FIX ---\n\n\n    print(f\"\\nüéß Sample {idx+1}: {clean_id} ({base_name})\")\n    print(f\"Input SNR: {in_snr:.2f} dB | Output SNR: {out_snr:.2f} dB | Œî: {out_snr-in_snr:.2f} dB\")\n\n    plt.figure(figsize=(15,3))\n    # Plot the normalized clean audio for a true comparison\n    plt.plot(clean_normalized, label=\"Clean (Normalized)\", color='green')\n    plt.plot(noisy, label=f\"Noisy ({in_snr:.2f} dB)\", color='red')\n    plt.plot(enhanced, label=f\"Denoised ({out_snr:.2f} dB)\", color='blue')\n    plt.legend(); plt.grid(True); plt.show()\n    \n    # Display audio (using original clean for listening)\n    display(ipd.Audio(clean_orig, rate=16000))\n    display(ipd.Audio(noisy, rate=16000))\n    display(ipd.Audio(enhanced, rate=16000))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T11:04:51.787527Z","iopub.execute_input":"2025-11-08T11:04:51.788227Z","iopub.status.idle":"2025-11-08T11:22:33.293028Z","shell.execute_reply.started":"2025-11-08T11:04:51.788201Z","shell.execute_reply":"2025-11-08T11:22:33.292449Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport librosa\nimport librosa.display\nfrom IPython.display import display, Audio\nimport os\n\ndef plot_individual_signals(clean, noisy, enhanced, sr=16000, title_suffix=\"\"):\n    \"\"\"Plot clean, noisy, and enhanced signals separately\"\"\"\n    \n    # Time vector for x-axis\n    time = np.arange(len(clean)) / sr\n    \n    # 1. Clean Signal Plot\n    plt.figure(figsize=(15, 4))\n    plt.plot(time, clean, color='green', linewidth=1.5, alpha=0.8)\n    plt.title(f\"Clean Speech Signal {title_suffix}\", fontsize=14, fontweight='bold')\n    plt.xlabel(\"Time (s)\")\n    plt.ylabel(\"Amplitude\")\n    plt.grid(True, alpha=0.3)\n    plt.xlim(0, time[-1])\n    plt.tight_layout()\n    plt.show()\n    \n    # 2. Noisy Signal Plot\n    plt.figure(figsize=(15, 4))\n    plt.plot(time, noisy, color='red', linewidth=1.5, alpha=0.8)\n    current_snr = calculate_snr_proper(clean, noisy)\n    plt.title(f\"Noisy Signal {title_suffix} (SNR: {current_snr:.2f} dB)\", \n              fontsize=14, fontweight='bold')\n    plt.xlabel(\"Time (s)\")\n    plt.ylabel(\"Amplitude\")\n    plt.grid(True, alpha=0.3)\n    plt.xlim(0, time[-1])\n    plt.tight_layout()\n    plt.show()\n    \n    # 3. Enhanced Signal Plot\n    plt.figure(figsize=(15, 4))\n    plt.plot(time, enhanced, color='blue', linewidth=1.5, alpha=0.8)\n    current_snr = calculate_snr_proper(clean, enhanced)\n    plt.title(f\"Enhanced Signal {title_suffix} (SNR: {current_snr:.2f} dB)\", \n              fontsize=14, fontweight='bold')\n    plt.xlabel(\"Time (s)\")\n    plt.ylabel(\"Amplitude\")\n    plt.grid(True, alpha=0.3)\n    plt.xlim(0, time[-1])\n    plt.tight_layout()\n    plt.show()\n\ndef plot_spectrogram_comparison(clean, noisy, enhanced, sr=16000, title_suffix=\"\"):\n    \"\"\"Plot spectrograms for all three signals in subplots\"\"\"\n    \n    fig, axes = plt.subplots(3, 1, figsize=(16, 12))\n    \n    # Spectrogram parameters\n    n_fft = 1024\n    hop_length = 256\n    \n    # Clean spectrogram\n    clean_spec = librosa.stft(clean, n_fft=n_fft, hop_length=hop_length)\n    clean_db = librosa.amplitude_to_db(np.abs(clean_spec), ref=np.max)\n    img1 = librosa.display.specshow(clean_db, sr=sr, hop_length=hop_length, \n                                   x_axis='time', y_axis='log', ax=axes[0])\n    axes[0].set_title(f\"Clean Spectrogram {title_suffix}\", fontsize=12, fontweight='bold')\n    axes[0].set_ylabel(\"Frequency (Hz)\")\n    plt.colorbar(img1, ax=axes[0])\n    \n    # Noisy spectrogram\n    noisy_spec = librosa.stft(noisy, n_fft=n_fft, hop_length=hop_length)\n    noisy_db = librosa.amplitude_to_db(np.abs(noisy_spec), ref=np.max)\n    img2 = librosa.display.specshow(noisy_db, sr=sr, hop_length=hop_length, \n                                   x_axis='time', y_axis='log', ax=axes[1])\n    axes[1].set_title(f\"Noisy Spectrogram {title_suffix} (SNR: {calculate_snr_proper(clean, noisy):.2f} dB)\", \n                     fontsize=12, fontweight='bold')\n    axes[1].set_ylabel(\"Frequency (Hz)\")\n    plt.colorbar(img2, ax=axes[1])\n    \n    # Enhanced spectrogram\n    enhanced_spec = librosa.stft(enhanced, n_fft=n_fft, hop_length=hop_length)\n    enhanced_db = librosa.amplitude_to_db(np.abs(enhanced_spec), ref=np.max)\n    img3 = librosa.display.specshow(enhanced_db, sr=sr, hop_length=hop_length, \n                                   x_axis='time', y_axis='log', ax=axes[2])\n    axes[2].set_title(f\"Enhanced Spectrogram {title_suffix} (SNR: {calculate_snr_proper(clean, enhanced):.2f} dB)\", \n                     fontsize=12, fontweight='bold')\n    axes[2].set_ylabel(\"Frequency (Hz)\")\n    axes[2].set_xlabel(\"Time (s)\")\n    plt.colorbar(img3, ax=axes[2])\n    \n    plt.tight_layout()\n    plt.show()\n\ndef plot_waveform_comparison(clean, noisy, enhanced, sr=16000, title_suffix=\"\"):\n    \"\"\"Plot all three signals together for comparison\"\"\"\n    \n    time = np.arange(len(clean)) / sr\n    \n    plt.figure(figsize=(16, 6))\n    \n    plt.plot(time, clean, label='Clean', color='green', linewidth=2, alpha=0.8)\n    plt.plot(time, noisy, label=f'Noisy (SNR: {calculate_snr_proper(clean, noisy):.2f} dB)', \n             color='red', linewidth=1.5, alpha=0.7)\n    plt.plot(time, enhanced, label=f'Enhanced (SNR: {calculate_snr_proper(clean, enhanced):.2f} dB)', \n             color='blue', linewidth=1.5, alpha=0.8)\n    \n    plt.title(f\"Waveform Comparison {title_suffix}\", fontsize=14, fontweight='bold')\n    plt.xlabel(\"Time (s)\")\n    plt.ylabel(\"Amplitude\")\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    plt.xlim(0, time[-1])\n    plt.tight_layout()\n    plt.show()\n\ndef plot_magnitude_spectrum(clean, noisy, enhanced, sr=16000, title_suffix=\"\"):\n    \"\"\"Plot magnitude spectrum comparison\"\"\"\n    \n    # Compute FFT\n    clean_fft = np.fft.fft(clean)\n    noisy_fft = np.fft.fft(noisy)\n    enhanced_fft = np.fft.fft(enhanced)\n    \n    # Frequency axis\n    freqs = np.fft.fftfreq(len(clean), 1/sr)\n    positive_freq_idx = (freqs > 0) & (freqs <= 8000)  # Focus on speech frequencies\n    \n    plt.figure(figsize=(14, 6))\n    \n    # Plot magnitude spectrum\n    plt.plot(freqs[positive_freq_idx], np.abs(clean_fft[positive_freq_idx]), \n             label='Clean', color='green', linewidth=2, alpha=0.8)\n    plt.plot(freqs[positive_freq_idx], np.abs(noisy_fft[positive_freq_idx]), \n             label='Noisy', color='red', linewidth=1.5, alpha=0.7)\n    plt.plot(freqs[positive_freq_idx], np.abs(enhanced_fft[positive_freq_idx]), \n             label='Enhanced', color='blue', linewidth=1.5, alpha=0.8)\n    \n    plt.title(f\"Magnitude Spectrum Comparison {title_suffix}\", fontsize=14, fontweight='bold')\n    plt.xlabel(\"Frequency (Hz)\")\n    plt.ylabel(\"Magnitude\")\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    plt.tight_layout()\n    plt.show()\n\ndef plot_snr_improvement_bar(snr_results):\n    \"\"\"Plot SNR improvement as bar chart\"\"\"\n    \n    samples = [f\"Sample {i+1}\" for i in range(len(snr_results))]\n    input_snrs = [result['input_snr'] for result in snr_results]\n    output_snrs = [result['output_snr'] for result in snr_results]\n    improvements = [result['improvement'] for result in snr_results]\n    \n    x = np.arange(len(samples))\n    width = 0.25\n    \n    plt.figure(figsize=(12, 6))\n    \n    plt.bar(x - width, input_snrs, width, label='Input SNR', color='red', alpha=0.7)\n    plt.bar(x, output_snrs, width, label='Output SNR', color='blue', alpha=0.7)\n    plt.bar(x + width, improvements, width, label='SNR Improvement', color='green', alpha=0.7)\n    \n    plt.xlabel('Samples')\n    plt.ylabel('SNR (dB)')\n    plt.title('SNR Improvement Across Samples', fontsize=14, fontweight='bold')\n    plt.xticks(x, samples)\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    \n    # Add value labels on bars\n    for i, (in_snr, out_snr, imp) in enumerate(zip(input_snrs, output_snrs, improvements)):\n        plt.text(i - width, in_snr + 0.5, f'{in_snr:.1f}', ha='center', va='bottom', fontweight='bold')\n        plt.text(i, out_snr + 0.5, f'{out_snr:.1f}', ha='center', va='bottom', fontweight='bold')\n        plt.text(i + width, imp + 0.5, f'+{imp:.1f}', ha='center', va='bottom', fontweight='bold')\n    \n    plt.tight_layout()\n    plt.show()\n\n# Enhanced evaluation function\ndef comprehensive_evaluation(model, num_samples=5):\n    \"\"\"Run comprehensive evaluation with all visualization types\"\"\"\n    \n    files = sorted(os.listdir(noisy_dir_stft))[:num_samples]\n    snr_results = []\n    \n    print(f\"üîä Evaluating {len(files)} samples...\")\n    \n    for idx, f in enumerate(files):\n        clean_id = f.split(\"_\")[0]\n        noisy_path = os.path.join(noisy_dir_stft, f)\n        phase_path = os.path.join(STFT_DIR, \"phase\", f.replace(\"_noisy_mag.npy\", \"_phase.npy\"))\n        clean_wav_path = os.path.join(CLEAN_DIR, clean_id + \".wav\")\n        \n        base_name = f.replace(\"_noisy_mag.npy\", \"\")\n        noisy_wav_path = os.path.join(MIX_DIR, base_name + \".wav\")\n        \n        print(f\"\\n{'='*60}\")\n        print(f\"üéß Processing Sample {idx+1}/{len(files)}: {base_name}\")\n        print(f\"{'='*60}\")\n        \n        # Reconstruct enhanced audio\n        enhanced_wav_path = reconstruct_audio(model, noisy_path, phase_path, ENHANCED_DIR)\n        \n        # Load all audio files\n        clean_orig, _ = librosa.load(clean_wav_path, sr=16000)\n        noisy, _ = librosa.load(noisy_wav_path, sr=16000)\n        enhanced, _ = librosa.load(enhanced_wav_path, sr=16000)\n        \n        # Align lengths and normalize\n        min_len = min(len(clean_orig), len(noisy), len(enhanced))\n        clean_orig = clean_orig[:min_len]\n        noisy = noisy[:min_len]\n        enhanced = enhanced[:min_len]\n        \n        clean_normalized = clean_orig / (np.max(np.abs(clean_orig)) + 1e-8)\n        \n        # Calculate SNR\n        in_snr = calculate_snr_proper(clean_normalized, noisy)\n        out_snr = calculate_snr_proper(clean_normalized, enhanced)\n        snr_improvement = out_snr - in_snr\n        \n        snr_results.append({\n            'sample': base_name,\n            'input_snr': in_snr,\n            'output_snr': out_snr,\n            'improvement': snr_improvement\n        })\n        \n        print(f\"üìä Results:\")\n        print(f\"   ‚Ä¢ Input SNR: {in_snr:.2f} dB\")\n        print(f\"   ‚Ä¢ Output SNR: {out_snr:.2f} dB\")\n        print(f\"   ‚Ä¢ SNR Improvement: {snr_improvement:+.2f} dB\")\n        \n        # Generate all plots for this sample\n        plot_individual_signals(clean_normalized, noisy, enhanced, title_suffix=f\"- {base_name}\")\n        plot_waveform_comparison(clean_normalized, noisy, enhanced, title_suffix=f\"- {base_name}\")\n        plot_spectrogram_comparison(clean_normalized, noisy, enhanced, title_suffix=f\"- {base_name}\")\n        plot_magnitude_spectrum(clean_normalized, noisy, enhanced, title_suffix=f\"- {base_name}\")\n        \n        # Display audio players\n        print(\"\\nüîä Audio Playback:\")\n        display(Audio(clean_orig, rate=16000))\n        display(Audio(noisy, rate=16000))\n        display(Audio(enhanced, rate=16000))\n    \n    # Summary plots\n    if len(snr_results) > 1:\n        print(f\"\\n{'='*60}\")\n        print(\"üìà SUMMARY STATISTICS\")\n        print(f\"{'='*60}\")\n        \n        avg_improvement = np.mean([r['improvement'] for r in snr_results])\n        max_improvement = np.max([r['improvement'] for r in snr_results])\n        min_improvement = np.min([r['improvement'] for r in snr_results])\n        \n        print(f\"Average SNR Improvement: {avg_improvement:.2f} dB\")\n        print(f\"Maximum SNR Improvement: {max_improvement:.2f} dB\")\n        print(f\"Minimum SNR Improvement: {min_improvement:.2f} dB\")\n        \n        plot_snr_improvement_bar(snr_results)\n    \n    return snr_results\n\n# Run the comprehensive evaluation\nprint(\"Starting comprehensive evaluation...\")\nsnr_results = comprehensive_evaluation(trained_model, num_samples=5)  # Change to 5 samples","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T12:13:38.750668Z","iopub.execute_input":"2025-11-08T12:13:38.751473Z","iopub.status.idle":"2025-11-08T12:13:52.994169Z","shell.execute_reply.started":"2025-11-08T12:13:38.751448Z","shell.execute_reply":"2025-11-08T12:13:52.993444Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Create directory for saving plots\nPLOTS_DIR = \"/kaggle/working/plots\"\nos.makedirs(PLOTS_DIR, exist_ok=True)\nprint(f\"üìÅ Plot directory created: {PLOTS_DIR}\")\n\ndef plot_individual_signals(clean, noisy, enhanced, sr=16000, title_suffix=\"\", save_plots=True):\n    \"\"\"Plot clean, noisy, and enhanced signals separately and save as PNG\"\"\"\n    \n    # Time vector for x-axis\n    time = np.arange(len(clean)) / sr\n    \n    # 1. Clean Signal Plot\n    plt.figure(figsize=(15, 4))\n    plt.plot(time, clean, color='green', linewidth=1.5, alpha=0.8)\n    plt.title(f\"Clean Speech Signal {title_suffix}\", fontsize=14, fontweight='bold')\n    plt.xlabel(\"Time (s)\")\n    plt.ylabel(\"Amplitude\")\n    plt.grid(True, alpha=0.3)\n    plt.xlim(0, time[-1])\n    plt.tight_layout()\n    \n    if save_plots:\n        clean_filename = f\"clean_signal_{title_suffix.replace(' ', '_').replace('-', '_')}.png\"\n        clean_filepath = os.path.join(PLOTS_DIR, clean_filename)\n        plt.savefig(clean_filepath, dpi=300, bbox_inches='tight', facecolor='white')\n        print(f\"üíæ Saved: {clean_filename}\")\n    plt.show()\n    plt.close()\n    \n    # 2. Noisy Signal Plot\n    plt.figure(figsize=(15, 4))\n    plt.plot(time, noisy, color='red', linewidth=1.5, alpha=0.8)\n    current_snr = calculate_snr_proper(clean, noisy)\n    plt.title(f\"Noisy Signal {title_suffix} (SNR: {current_snr:.2f} dB)\", \n              fontsize=14, fontweight='bold')\n    plt.xlabel(\"Time (s)\")\n    plt.ylabel(\"Amplitude\")\n    plt.grid(True, alpha=0.3)\n    plt.xlim(0, time[-1])\n    plt.tight_layout()\n    \n    if save_plots:\n        noisy_filename = f\"noisy_signal_{title_suffix.replace(' ', '_').replace('-', '_')}.png\"\n        noisy_filepath = os.path.join(PLOTS_DIR, noisy_filename)\n        plt.savefig(noisy_filepath, dpi=300, bbox_inches='tight', facecolor='white')\n        print(f\"üíæ Saved: {noisy_filename}\")\n    plt.show()\n    plt.close()\n    \n    # 3. Enhanced Signal Plot\n    plt.figure(figsize=(15, 4))\n    plt.plot(time, enhanced, color='blue', linewidth=1.5, alpha=0.8)\n    current_snr = calculate_snr_proper(clean, enhanced)\n    plt.title(f\"Enhanced Signal {title_suffix} (SNR: {current_snr:.2f} dB)\", \n              fontsize=14, fontweight='bold')\n    plt.xlabel(\"Time (s)\")\n    plt.ylabel(\"Amplitude\")\n    plt.grid(True, alpha=0.3)\n    plt.xlim(0, time[-1])\n    plt.tight_layout()\n    \n    if save_plots:\n        enhanced_filename = f\"enhanced_signal_{title_suffix.replace(' ', '_').replace('-', '_')}.png\"\n        enhanced_filepath = os.path.join(PLOTS_DIR, enhanced_filename)\n        plt.savefig(enhanced_filepath, dpi=300, bbox_inches='tight', facecolor='white')\n        print(f\"üíæ Saved: {enhanced_filename}\")\n    plt.show()\n    plt.close()\n\ndef plot_spectrogram_comparison(clean, noisy, enhanced, sr=16000, title_suffix=\"\", save_plots=True):\n    \"\"\"Plot spectrograms for all three signals in subplots and save as PNG\"\"\"\n    \n    fig, axes = plt.subplots(3, 1, figsize=(16, 12))\n    \n    # Spectrogram parameters\n    n_fft = 1024\n    hop_length = 256\n    \n    # Clean spectrogram\n    clean_spec = librosa.stft(clean, n_fft=n_fft, hop_length=hop_length)\n    clean_db = librosa.amplitude_to_db(np.abs(clean_spec), ref=np.max)\n    img1 = librosa.display.specshow(clean_db, sr=sr, hop_length=hop_length, \n                                   x_axis='time', y_axis='log', ax=axes[0])\n    axes[0].set_title(f\"Clean Spectrogram {title_suffix}\", fontsize=12, fontweight='bold')\n    axes[0].set_ylabel(\"Frequency (Hz)\")\n    plt.colorbar(img1, ax=axes[0])\n    \n    # Noisy spectrogram\n    noisy_spec = librosa.stft(noisy, n_fft=n_fft, hop_length=hop_length)\n    noisy_db = librosa.amplitude_to_db(np.abs(noisy_spec), ref=np.max)\n    img2 = librosa.display.specshow(noisy_db, sr=sr, hop_length=hop_length, \n                                   x_axis='time', y_axis='log', ax=axes[1])\n    axes[1].set_title(f\"Noisy Spectrogram {title_suffix} (SNR: {calculate_snr_proper(clean, noisy):.2f} dB)\", \n                     fontsize=12, fontweight='bold')\n    axes[1].set_ylabel(\"Frequency (Hz)\")\n    plt.colorbar(img2, ax=axes[1])\n    \n    # Enhanced spectrogram\n    enhanced_spec = librosa.stft(enhanced, n_fft=n_fft, hop_length=hop_length)\n    enhanced_db = librosa.amplitude_to_db(np.abs(enhanced_spec), ref=np.max)\n    img3 = librosa.display.specshow(enhanced_db, sr=sr, hop_length=hop_length, \n                                   x_axis='time', y_axis='log', ax=axes[2])\n    axes[2].set_title(f\"Enhanced Spectrogram {title_suffix} (SNR: {calculate_snr_proper(clean, enhanced):.2f} dB)\", \n                     fontsize=12, fontweight='bold')\n    axes[2].set_ylabel(\"Frequency (Hz)\")\n    axes[2].set_xlabel(\"Time (s)\")\n    plt.colorbar(img3, ax=axes[2])\n    \n    plt.tight_layout()\n    \n    if save_plots:\n        spec_filename = f\"spectrogram_comparison_{title_suffix.replace(' ', '_').replace('-', '_')}.png\"\n        spec_filepath = os.path.join(PLOTS_DIR, spec_filename)\n        plt.savefig(spec_filepath, dpi=300, bbox_inches='tight', facecolor='white')\n        print(f\"üíæ Saved: {spec_filename}\")\n    \n    plt.show()\n    plt.close()\n\ndef plot_waveform_comparison(clean, noisy, enhanced, sr=16000, title_suffix=\"\", save_plots=True):\n    \"\"\"Plot all three signals together for comparison and save as PNG\"\"\"\n    \n    time = np.arange(len(clean)) / sr\n    \n    plt.figure(figsize=(16, 6))\n    \n    plt.plot(time, clean, label='Clean', color='green', linewidth=2, alpha=0.8)\n    plt.plot(time, noisy, label=f'Noisy (SNR: {calculate_snr_proper(clean, noisy):.2f} dB)', \n             color='red', linewidth=1.5, alpha=0.7)\n    plt.plot(time, enhanced, label=f'Enhanced (SNR: {calculate_snr_proper(clean, enhanced):.2f} dB)', \n             color='blue', linewidth=1.5, alpha=0.8)\n    \n    plt.title(f\"Waveform Comparison {title_suffix}\", fontsize=14, fontweight='bold')\n    plt.xlabel(\"Time (s)\")\n    plt.ylabel(\"Amplitude\")\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    plt.xlim(0, time[-1])\n    plt.tight_layout()\n    \n    if save_plots:\n        waveform_filename = f\"waveform_comparison_{title_suffix.replace(' ', '_').replace('-', '_')}.png\"\n        waveform_filepath = os.path.join(PLOTS_DIR, waveform_filename)\n        plt.savefig(waveform_filepath, dpi=300, bbox_inches='tight', facecolor='white')\n        print(f\"üíæ Saved: {waveform_filename}\")\n    \n    plt.show()\n    plt.close()\n\ndef plot_magnitude_spectrum(clean, noisy, enhanced, sr=16000, title_suffix=\"\", save_plots=True):\n    \"\"\"Plot magnitude spectrum comparison and save as PNG\"\"\"\n    \n    # Compute FFT\n    clean_fft = np.fft.fft(clean)\n    noisy_fft = np.fft.fft(noisy)\n    enhanced_fft = np.fft.fft(enhanced)\n    \n    # Frequency axis\n    freqs = np.fft.fftfreq(len(clean), 1/sr)\n    positive_freq_idx = (freqs > 0) & (freqs <= 8000)  # Focus on speech frequencies\n    \n    plt.figure(figsize=(14, 6))\n    \n    # Plot magnitude spectrum\n    plt.plot(freqs[positive_freq_idx], np.abs(clean_fft[positive_freq_idx]), \n             label='Clean', color='green', linewidth=2, alpha=0.8)\n    plt.plot(freqs[positive_freq_idx], np.abs(noisy_fft[positive_freq_idx]), \n             label='Noisy', color='red', linewidth=1.5, alpha=0.7)\n    plt.plot(freqs[positive_freq_idx], np.abs(enhanced_fft[positive_freq_idx]), \n             label='Enhanced', color='blue', linewidth=1.5, alpha=0.8)\n    \n    plt.title(f\"Magnitude Spectrum Comparison {title_suffix}\", fontsize=14, fontweight='bold')\n    plt.xlabel(\"Frequency (Hz)\")\n    plt.ylabel(\"Magnitude\")\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    plt.tight_layout()\n    \n    if save_plots:\n        spectrum_filename = f\"magnitude_spectrum_{title_suffix.replace(' ', '_').replace('-', '_')}.png\"\n        spectrum_filepath = os.path.join(PLOTS_DIR, spectrum_filename)\n        plt.savefig(spectrum_filepath, dpi=300, bbox_inches='tight', facecolor='white')\n        print(f\"üíæ Saved: {spectrum_filename}\")\n    \n    plt.show()\n    plt.close()\n\ndef plot_snr_improvement_bar(snr_results, save_plots=True):\n    \"\"\"Plot SNR improvement as bar chart and save as PNG\"\"\"\n    \n    samples = [f\"Sample {i+1}\" for i in range(len(snr_results))]\n    input_snrs = [result['input_snr'] for result in snr_results]\n    output_snrs = [result['output_snr'] for result in snr_results]\n    improvements = [result['improvement'] for result in snr_results]\n    \n    x = np.arange(len(samples))\n    width = 0.25\n    \n    plt.figure(figsize=(12, 6))\n    \n    plt.bar(x - width, input_snrs, width, label='Input SNR', color='red', alpha=0.7)\n    plt.bar(x, output_snrs, width, label='Output SNR', color='blue', alpha=0.7)\n    plt.bar(x + width, improvements, width, label='SNR Improvement', color='green', alpha=0.7)\n    \n    plt.xlabel('Samples')\n    plt.ylabel('SNR (dB)')\n    plt.title('SNR Improvement Across Samples', fontsize=14, fontweight='bold')\n    plt.xticks(x, samples)\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    \n    # Add value labels on bars\n    for i, (in_snr, out_snr, imp) in enumerate(zip(input_snrs, output_snrs, improvements)):\n        plt.text(i - width, in_snr + 0.5, f'{in_snr:.1f}', ha='center', va='bottom', fontweight='bold')\n        plt.text(i, out_snr + 0.5, f'{out_snr:.1f}', ha='center', va='bottom', fontweight='bold')\n        plt.text(i + width, imp + 0.5, f'+{imp:.1f}', ha='center', va='bottom', fontweight='bold')\n    \n    plt.tight_layout()\n    \n    if save_plots:\n        snr_filename = \"snr_improvement_summary.png\"\n        snr_filepath = os.path.join(PLOTS_DIR, snr_filename)\n        plt.savefig(snr_filepath, dpi=300, bbox_inches='tight', facecolor='white')\n        print(f\"üíæ Saved: {snr_filename}\")\n    \n    plt.show()\n    plt.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T12:20:07.026204Z","iopub.execute_input":"2025-11-08T12:20:07.026528Z","iopub.status.idle":"2025-11-08T12:20:07.055344Z","shell.execute_reply.started":"2025-11-08T12:20:07.026508Z","shell.execute_reply":"2025-11-08T12:20:07.054618Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def comprehensive_evaluation_with_saving(model, num_samples=5, save_plots=True):\n    \"\"\"Run comprehensive evaluation with automatic plot saving\"\"\"\n    \n    files = sorted(os.listdir(noisy_dir_stft))[:num_samples]\n    snr_results = []\n    \n    print(f\"üîä Evaluating {len(files)} samples...\")\n    print(f\"üìÅ Saving plots to: {PLOTS_DIR}\")\n    \n    for idx, f in enumerate(files):\n        clean_id = f.split(\"_\")[0]\n        noisy_path = os.path.join(noisy_dir_stft, f)\n        phase_path = os.path.join(STFT_DIR, \"phase\", f.replace(\"_noisy_mag.npy\", \"_phase.npy\"))\n        clean_wav_path = os.path.join(CLEAN_DIR, clean_id + \".wav\")\n        \n        base_name = f.replace(\"_noisy_mag.npy\", \"\")\n        noisy_wav_path = os.path.join(MIX_DIR, base_name + \".wav\")\n        \n        print(f\"\\n{'='*60}\")\n        print(f\"üéß Processing Sample {idx+1}/{len(files)}: {base_name}\")\n        print(f\"{'='*60}\")\n        \n        # Reconstruct enhanced audio\n        enhanced_wav_path = reconstruct_audio(model, noisy_path, phase_path, ENHANCED_DIR)\n        \n        # Load all audio files\n        clean_orig, _ = librosa.load(clean_wav_path, sr=16000)\n        noisy, _ = librosa.load(noisy_wav_path, sr=16000)\n        enhanced, _ = librosa.load(enhanced_wav_path, sr=16000)\n        \n        # Align lengths and normalize\n        min_len = min(len(clean_orig), len(noisy), len(enhanced))\n        clean_orig = clean_orig[:min_len]\n        noisy = noisy[:min_len]\n        enhanced = enhanced[:min_len]\n        \n        clean_normalized = clean_orig / (np.max(np.abs(clean_orig)) + 1e-8)\n        \n        # Calculate SNR\n        in_snr = calculate_snr_proper(clean_normalized, noisy)\n        out_snr = calculate_snr_proper(clean_normalized, enhanced)\n        snr_improvement = out_snr - in_snr\n        \n        snr_results.append({\n            'sample': base_name,\n            'input_snr': in_snr,\n            'output_snr': out_snr,\n            'improvement': snr_improvement\n        })\n        \n        print(f\"üìä Results:\")\n        print(f\"   ‚Ä¢ Input SNR: {in_snr:.2f} dB\")\n        print(f\"   ‚Ä¢ Output SNR: {out_snr:.2f} dB\")\n        print(f\"   ‚Ä¢ SNR Improvement: {snr_improvement:+.2f} dB\")\n        \n        # Clean up the title suffix for filenames\n        clean_title_suffix = base_name.replace(\" \", \"_\").replace(\"-\", \"_\")\n        \n        # Generate all plots for this sample with saving\n        plot_individual_signals(clean_normalized, noisy, enhanced, \n                               title_suffix=clean_title_suffix, save_plots=save_plots)\n        plot_waveform_comparison(clean_normalized, noisy, enhanced, \n                                title_suffix=clean_title_suffix, save_plots=save_plots)\n        plot_spectrogram_comparison(clean_normalized, noisy, enhanced, \n                                   title_suffix=clean_title_suffix, save_plots=save_plots)\n        plot_magnitude_spectrum(clean_normalized, noisy, enhanced, \n                               title_suffix=clean_title_suffix, save_plots=save_plots)\n        \n        # Display audio players\n        print(\"\\nüîä Audio Playback:\")\n        display(Audio(clean_orig, rate=16000))\n        display(Audio(noisy, rate=16000))\n        display(Audio(enhanced, rate=16000))\n    \n    # Summary plots\n    if len(snr_results) > 1:\n        print(f\"\\n{'='*60}\")\n        print(\"üìà SUMMARY STATISTICS\")\n        print(f\"{'='*60}\")\n        \n        avg_improvement = np.mean([r['improvement'] for r in snr_results])\n        max_improvement = np.max([r['improvement'] for r in snr_results])\n        min_improvement = np.min([r['improvement'] for r in snr_results])\n        \n        print(f\"Average SNR Improvement: {avg_improvement:.2f} dB\")\n        print(f\"Maximum SNR Improvement: {max_improvement:.2f} dB\")\n        print(f\"Minimum SNR Improvement: {min_improvement:.2f} dB\")\n        \n        plot_snr_improvement_bar(snr_results, save_plots=save_plots)\n    \n    # Print summary of saved files\n    if save_plots:\n        saved_files = os.listdir(PLOTS_DIR)\n        print(f\"\\nüìÇ Total plots saved: {len(saved_files)}\")\n        print(\"üìä File breakdown:\")\n        png_files = [f for f in saved_files if f.endswith('.png')]\n        for file_type in ['clean_signal', 'noisy_signal', 'enhanced_signal', \n                         'waveform_comparison', 'spectrogram_comparison', 'magnitude_spectrum']:\n            count = len([f for f in png_files if f.startswith(file_type)])\n            if count > 0:\n                print(f\"   ‚Ä¢ {file_type}: {count} files\")\n    \n    return snr_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T12:20:37.827085Z","iopub.execute_input":"2025-11-08T12:20:37.827792Z","iopub.status.idle":"2025-11-08T12:20:37.840185Z","shell.execute_reply.started":"2025-11-08T12:20:37.827768Z","shell.execute_reply":"2025-11-08T12:20:37.839437Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_training_progress_with_saving(train_losses, val_losses, save_plots=True):\n    \"\"\"Plot training progress and save as PNG\"\"\"\n    \n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n    \n    epochs = range(1, len(train_losses) + 1)\n    \n    # 1. Loss curves\n    ax1.plot(epochs, train_losses, 'b-', label='Training Loss', linewidth=2)\n    ax1.plot(epochs, val_losses, 'r-', label='Validation Loss', linewidth=2)\n    ax1.set_xlabel('Epoch')\n    ax1.set_ylabel('Loss')\n    ax1.set_title('Training Progress', fontweight='bold')\n    ax1.legend()\n    ax1.grid(True, alpha=0.3)\n    \n    # 2. Log scale loss\n    ax2.semilogy(epochs, train_losses, 'b-', label='Training Loss', linewidth=2)\n    ax2.semilogy(epochs, val_losses, 'r-', label='Validation Loss', linewidth=2)\n    ax2.set_xlabel('Epoch')\n    ax2.set_ylabel('Loss (log scale)')\n    ax2.set_title('Training Progress (Log Scale)', fontweight='bold')\n    ax2.legend()\n    ax2.grid(True, alpha=0.3)\n    \n    # 3. Loss difference\n    loss_diff = [val - train for train, val in zip(train_losses, val_losses)]\n    ax3.plot(epochs, loss_diff, 'g-', linewidth=2)\n    ax3.set_xlabel('Epoch')\n    ax3.set_ylabel('Validation - Training Loss')\n    ax3.set_title('Generalization Gap', fontweight='bold')\n    ax3.grid(True, alpha=0.3)\n    \n    # 4. Moving average\n    window = 5\n    if len(train_losses) > window:\n        train_ma = np.convolve(train_losses, np.ones(window)/window, mode='valid')\n        val_ma = np.convolve(val_losses, np.ones(window)/window, mode='valid')\n        ax4.plot(epochs[window-1:], train_ma, 'b-', label='Train MA', linewidth=2)\n        ax4.plot(epochs[window-1:], val_ma, 'r-', label='Val MA', linewidth=2)\n        ax4.set_xlabel('Epoch')\n        ax4.set_ylabel('Loss (Moving Average)')\n        ax4.set_title(f'Moving Average (Window={window})', fontweight='bold')\n        ax4.legend()\n        ax4.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    \n    if save_plots:\n        training_filename = \"training_progress_analysis.png\"\n        training_filepath = os.path.join(PLOTS_DIR, training_filename)\n        plt.savefig(training_filepath, dpi=300, bbox_inches='tight', facecolor='white')\n        print(f\"üíæ Saved: {training_filename}\")\n    \n    plt.show()\n    plt.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T12:21:23.572967Z","iopub.execute_input":"2025-11-08T12:21:23.573240Z","iopub.status.idle":"2025-11-08T12:21:23.582733Z","shell.execute_reply.started":"2025-11-08T12:21:23.573220Z","shell.execute_reply":"2025-11-08T12:21:23.581877Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Run the comprehensive evaluation with plot saving\nprint(\"üöÄ Starting comprehensive evaluation with plot saving...\")\nsnr_results = comprehensive_evaluation_with_saving(trained_model, num_samples=5, save_plots=True)\n\n# If you have training history, save training plots too\ntry:\n    plot_training_progress_with_saving(train_losses, val_losses, save_plots=True)\nexcept NameError:\n    print(\"‚ö†Ô∏è Training history not available for plotting\")\n\n# List all saved files\nprint(f\"\\nüéâ Evaluation complete! All plots saved to: {PLOTS_DIR}\")\nsaved_files = sorted(os.listdir(PLOTS_DIR))\nprint(f\"üìÑ Total PNG files created: {len([f for f in saved_files if f.endswith('.png')])}\")\n\n# Show file listing\nprint(\"\\nüìã Saved files:\")\nfor i, file in enumerate(saved_files[:20]):  # Show first 20 files\n    print(f\"   {i+1:2d}. {file}\")\nif len(saved_files) > 20:\n    print(f\"   ... and {len(saved_files) - 20} more files\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T12:21:46.600701Z","iopub.execute_input":"2025-11-08T12:21:46.601425Z","iopub.status.idle":"2025-11-08T12:22:32.747780Z","shell.execute_reply.started":"2025-11-08T12:21:46.601374Z","shell.execute_reply":"2025-11-08T12:22:32.747151Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport librosa\n\n# Load the signals\n\nclean_path = \"/kaggle/input/datasetnew/clean_wav/clean_wav/03-01-01-01-01-01-02.wav\"\nnoisy_path = \"/kaggle/working/mixed_snr_wav/03-01-01-01-01-01-02_ambience_snr-5dB.wav\"\nenhanced_path = \"/kaggle/working/enhanced_audio/03-01-01-01-01-01-02_ambience_snr-5dB_enhanced.wav\"\n\nsr = 16000\nclean, _ = librosa.load(clean_path, sr=sr)\nnoisy, _ = librosa.load(noisy_path, sr=sr)\nenhanced, _ = librosa.load(enhanced_path, sr=sr)\n\n# Trim signals to same length\nmin_len = min(len(clean), len(noisy), len(enhanced))\nclean = clean[:min_len]\nnoisy = noisy[:min_len]\nenhanced = enhanced[:min_len]\n\n# Normalize clean signal\nclean_norm = clean / (np.max(np.abs(clean)) + 1e-8)\n\n# Define simple SNR calculation\ndef snr_db(reference, estimate):\n    noise = reference - estimate\n    snr = 10 * np.log10(np.sum(reference**2) / (np.sum(noise**2) + 1e-8))\n    return snr\n\n# Compute SNRs\ninput_snr_check = snr_db(clean_norm, noisy)\noutput_snr_check = snr_db(clean_norm, enhanced)\nimprovement_check = output_snr_check - input_snr_check\n\nprint(f\"Input SNR (manual check): {input_snr_check:.2f} dB\")\nprint(f\"Output SNR (manual check): {output_snr_check:.2f} dB\")\nprint(f\"SNR Improvement: {improvement_check:.2f} dB\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T12:37:26.767807Z","iopub.execute_input":"2025-11-08T12:37:26.768170Z","iopub.status.idle":"2025-11-08T12:37:26.788782Z","shell.execute_reply.started":"2025-11-08T12:37:26.768144Z","shell.execute_reply":"2025-11-08T12:37:26.788067Z"}},"outputs":[],"execution_count":null}]}